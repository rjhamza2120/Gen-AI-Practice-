{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\Generative\\\\Practice\\\\env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "ar_tool = ArxivQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://www.britannica.com/technology/artificial-intelligence\")\n",
    "docs=loader.load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000,\n",
    "                                          chunk_overlap=200)\n",
    "splitted_docs = splitter.split_documents(docs)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "db = FAISS.from_documents(splitted_docs,embeddings)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"AI_Search\",\n",
    "    \"Search for information about Artificial Intelligence. For any questions about AI or ML, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki_tool, ar_tool, retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'f:\\\\Generative\\\\Practice\\\\env\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='AI_Search', description='Search for information about Artificial Intelligence. For any questions about AI or ML, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000026DA37D0B80>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026DECA0A060>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000026DA37D0CC0>, retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000026DECA0A060>), document_prompt=PromptTemplate(input_variables=['page_content'], template='{page_content}'), document_separator='\\n\\n'))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Generative\\Practice\\env\\Lib\\site-packages\\langsmith\\client.py:322: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "f:\\Generative\\Practice\\env\\Lib\\site-packages\\langsmith\\client.py:5301: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_functions_agent\n",
    "\n",
    "agent = create_openai_functions_agent(model, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `AI_Search` with `{'query': 'Transformers AI'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m(Show more)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSee all related content →\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tAsk the Chatbot a Question\n",
      "\n",
      "\n",
      "\n",
      "\tAsk the Chatbot a Question\n",
      "\n",
      "\n",
      "\t\t\t\tTop Questions\n",
      "\t\t\t What is artificial intelligence? Artificial intelligence is the ability of a computer or computer-controlled robot to perform tasks that are commonly associated with the intellectual processes characteristic of humans, such as the ability to reason. Although there are as yet no AIs that match full human flexibility over wider domains or in tasks requiring much everyday knowledge, some AIs perform specific tasks as well as humans. Learn more.  Are artificial intelligence and machine learning the same? No, artificial intelligence and machine learning are not the same, but they are closely related. Machine learning is the method to train a computer to learn from its inputs but without explicit programming for every circumstance. Machine learning helps a computer to achieve artificial intelligence. \n",
      "\n",
      "\t\t\tRecent News\n",
      "\n",
      "Sep 12, 2024\n",
      "•\n",
      "Article History\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "\t\t\tTable of Contents\n",
      "\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\tartificial intelligence \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "See all media\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Key People: \n",
      "Geoffrey Hinton\n",
      "Marvin Minsky\n",
      "Edward Albert Feigenbaum\n",
      "Allen Newell\n",
      "John McCarthy\n",
      "\n",
      "\n",
      "(Show more)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Related Topics: \n",
      "history of artificial intelligence (AI)\n",
      "computational aesthetics\n",
      "prompt engineering\n",
      "three laws of robotics\n",
      "generative AI\n",
      "\n",
      "\n",
      "(Show more)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSee all related content →\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tAsk the Chatbot a Question\n",
      "\n",
      "\n",
      "\n",
      "\tAsk the Chatbot a Question\n",
      "\n",
      "Facebook\n",
      "X\n",
      "\n",
      "URL\n",
      "https://www.britannica.com/technology/artificial-intelligence\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "    \n",
      "            Feedback\n",
      "        \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "                    External Websites\n",
      "                \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\tFeedback\n",
      "\t\t\n",
      "\n",
      "\n",
      "\t\t\t\tCorrections? Updates? Omissions? Let us know if you have suggestions to improve this article (requires login).\n",
      "\t\t\t\n",
      "\n",
      "Feedback Type\n",
      "\n",
      "Select a type (Required)\n",
      "Factual Correction\n",
      "Spelling/Grammar Correction\n",
      "Link Correction\n",
      "Additional Information\n",
      "Other\n",
      "\n",
      "\n",
      "Your Feedback\n",
      "\n",
      "Submit Feedback\n",
      "\n",
      "\n",
      "Thank you for your feedback\n",
      "Our editors will review what you’ve submitted and determine whether to revise the article.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                    External Websites\n",
      "\n",
      "Recent News\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSep. 12, 2024, 4:47 PM ET (AP)\n",
      "\t\t\t\t\t\n",
      "Tech companies commit to fighting harmful AI sexual imagery by curbing nudity from datasets\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSep. 12, 2024, 9:54 AM ET (AP)\n",
      "\t\t\t\t\t\n",
      "Most Americans don't trust AI-powered election information: AP-NORC/USAFacts survey\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSep. 12, 2024, 5:44 AM ET (AP)\n",
      "\t\t\t\t\t\n",
      "Google's AI model faces European Union scrutiny from privacy watchdog\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSep. 9, 2024, 8:54 PM ET (AP)\n",
      "\t\t\t\t\t\n",
      "Apple embraces the AI craze with its newly unleashed iPhone 16 lineup\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\t\t\tSep. 5, 2024, 12:24 PM ET (AP)\n",
      "\t\t\t\t\t\n",
      "Correction: AI-Safety-Math story\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Transformers (machine learning)'}`\n",
      "responded: It appears that the AI_Search function did not provide a clear answer to the question. Let's try to get more information about Transformers from Wikipedia.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Transformer (deep learning architecture)\n",
      "Summary: A transformer is a deep learning architecture developed by researchers at Google and based on the multi-head attention mechanism, proposed in a \u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Multi-head attention'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Attention (machine learning)\n",
      "Summary: Attention is a machine learning method that determines the relative importance of each component in a sequence relative to the other components in that sequ\u001b[0m\u001b[32;1m\u001b[1;3mThe Transformers architecture is a type of deep learning model that uses self-attention mechanisms to process input sequences. It was first introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017. The model consists of an encoder and a decoder, and it uses a self-attention mechanism to weigh the importance of different input elements when generating the output sequence.\n",
      "\n",
      "The Transformer architecture has several key components:\n",
      "\n",
      "1. Self-Attention Mechanism: This is the core component of the Transformer architecture. It allows the model to weigh the importance of different input elements when generating the output sequence.\n",
      "2. Encoder: The encoder is responsible for processing the input sequence and generating a set of vectors that represent the input.\n",
      "3. Decoder: The decoder is responsible for generating the output sequence based on the vectors generated by the encoder.\n",
      "4. Positional Encoding: This is a mechanism that adds positional information to the input sequence, allowing the model to understand the order of the elements in the sequence.\n",
      "\n",
      "The Transformer architecture has several advantages over traditional recurrent neural networks (RNNs), including:\n",
      "\n",
      "1. Parallelization: The Transformer architecture can be parallelized more easily than RNNs, making it faster to train.\n",
      "2. Scalability: The Transformer architecture can handle longer input sequences than RNNs, making it more suitable for tasks such as machine translation.\n",
      "3. Flexibility: The Transformer architecture can be used for a wide range of tasks, including machine translation, text classification, and question answering.\n",
      "\n",
      "However, the Transformer architecture also has some disadvantages, including:\n",
      "\n",
      "1. Computational Cost: The Transformer architecture requires more computational resources than RNNs, making it more expensive to train.\n",
      "2. Memory Requirements: The Transformer architecture requires more memory than RNNs, making it more challenging to train on large datasets.\n",
      "\n",
      "Overall, the Transformer architecture is a powerful tool for natural language processing tasks, and it has been widely adopted in the field.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are Transformers?',\n",
       " 'output': 'The Transformers architecture is a type of deep learning model that uses self-attention mechanisms to process input sequences. It was first introduced in the paper \"Attention Is All You Need\" by Vaswani et al. in 2017. The model consists of an encoder and a decoder, and it uses a self-attention mechanism to weigh the importance of different input elements when generating the output sequence.\\n\\nThe Transformer architecture has several key components:\\n\\n1. Self-Attention Mechanism: This is the core component of the Transformer architecture. It allows the model to weigh the importance of different input elements when generating the output sequence.\\n2. Encoder: The encoder is responsible for processing the input sequence and generating a set of vectors that represent the input.\\n3. Decoder: The decoder is responsible for generating the output sequence based on the vectors generated by the encoder.\\n4. Positional Encoding: This is a mechanism that adds positional information to the input sequence, allowing the model to understand the order of the elements in the sequence.\\n\\nThe Transformer architecture has several advantages over traditional recurrent neural networks (RNNs), including:\\n\\n1. Parallelization: The Transformer architecture can be parallelized more easily than RNNs, making it faster to train.\\n2. Scalability: The Transformer architecture can handle longer input sequences than RNNs, making it more suitable for tasks such as machine translation.\\n3. Flexibility: The Transformer architecture can be used for a wide range of tasks, including machine translation, text classification, and question answering.\\n\\nHowever, the Transformer architecture also has some disadvantages, including:\\n\\n1. Computational Cost: The Transformer architecture requires more computational resources than RNNs, making it more expensive to train.\\n2. Memory Requirements: The Transformer architecture requires more memory than RNNs, making it more challenging to train on large datasets.\\n\\nOverall, the Transformer architecture is a powerful tool for natural language processing tasks, and it has been widely adopted in the field.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What are Transformers?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m<arxiv>{\"query\": \"QLORA technique of quantization\"}</arxiv>\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Question:\n",
      "What is QLORA technique of quantization?\n",
      "Answer:\n",
      "<arxiv>{\"query\": \"QLORA technique of quantization\"}</arxiv>\n"
     ]
    }
   ],
   "source": [
    "answer=agent_executor.invoke({\"input\":\"What is QLORA technique of quantization?\"})\n",
    "print(f\"Question:\\n{answer['input']}\")\n",
    "print(f\"Answer:\\n{answer['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
